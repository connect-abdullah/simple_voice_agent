<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Agent - Web Frontend</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 40px;
            max-width: 600px;
            width: 90%;
            text-align: center;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        }
        
        h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            background: linear-gradient(45deg, #fff, #f0f0f0);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        
        .subtitle {
            font-size: 1.1rem;
            opacity: 0.8;
            margin-bottom: 40px;
        }
        
        .input-section {
            margin-bottom: 30px;
        }
        
        .voice-selection {
            margin-bottom: 20px;
            text-align: left;
        }
        
        .voice-selection label {
            display: block;
            margin-bottom: 8px;
            font-weight: 600;
            font-size: 16px;
        }
        
        select {
            width: 100%;
            padding: 12px;
            border: none;
            border-radius: 10px;
            font-size: 16px;
            background: rgba(255, 255, 255, 0.9);
            color: #333;
            cursor: pointer;
        }
        
        select:focus {
            outline: none;
            box-shadow: 0 0 0 3px rgba(255, 255, 255, 0.3);
        }
        
        .buttons {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin-top: 20px;
        }
        
        button {
            padding: 15px 30px;
            border: none;
            border-radius: 10px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .primary-btn {
            background: linear-gradient(45deg, #4CAF50, #45a049);
            color: white;
        }
        
        .record-btn {
            background: linear-gradient(45deg, #f44336, #da190b);
            color: white;
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
        }
        
        button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }
        
        .status {
            margin-top: 30px;
            padding: 20px;
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.1);
            min-height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top-color: white;
            animation: spin 1s ease-in-out infinite;
            margin-right: 10px;
        }
        
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        
        .audio-indicator {
            background: rgba(76, 175, 80, 0.2);
            border: 2px solid #4CAF50;
            color: #4CAF50;
            font-weight: bold;
        }
        
        .error {
            background: rgba(244, 67, 54, 0.2);
            border: 2px solid #f44336;
            color: #f44336;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Voice Agent</h1>
        <p class="subtitle">Speak to the AI - It will respond with voice</p>
        
        <div class="input-section">
            <div class="voice-selection">
                <label for="voiceSelect">üéµ AI Voice:</label>
                <select id="voiceSelect">
                    <option value="21m00Tcm4TlvDq8ikWAM">Rachel - Calm and professional</option>
                    <option value="AZnzlk1XvdvUeBnXmlld">Domi - Strong and confident</option>
                    <option value="N2lVS1w4EtoT3dr4eOWO">Callum - Gravelly with edge</option>
                </select>
            </div>
            <div class="buttons">
                <button id="recordBtn" class="record-btn">üé§ Start Recording</button>
            </div>
        </div>
        
        <div id="status" class="status">
            Ready to chat! üöÄ
        </div>
    </div>

    <script>
        const voiceSelect = document.getElementById('voiceSelect');
        const recordBtn = document.getElementById('recordBtn');
        const status = document.getElementById('status');
        
        const WS_URL = 'ws://localhost:8000/stream';
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let audioQueue = [];
        let isPlayingAudio = false;
        
        // Record audio
        recordBtn.addEventListener('click', () => {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        });
        
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    transcribeAudio(audioBlob);
                    stream.getTracks().forEach(track => track.stop());
                };
                
                mediaRecorder.start();
                isRecording = true;
                recordBtn.textContent = '‚èπÔ∏è Stop Recording';
                recordBtn.style.background = 'linear-gradient(45deg, #ff9800, #f57c00)';
                status.innerHTML = 'üé§ Recording... Click stop when done';
                
            } catch (error) {
                console.error('Error accessing microphone:', error);
                status.innerHTML = '‚ùå Microphone access denied';
                status.className = 'status error';
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                recordBtn.textContent = 'üé§ Record Audio';
                recordBtn.style.background = 'linear-gradient(45deg, #f44336, #da190b)';
                status.innerHTML = '<div class="loading"></div>Processing audio...';
            }
        }
        
        async function transcribeAudio(audioBlob) {
            try {
                const formData = new FormData();
                formData.append('audio', audioBlob, 'recording.wav');
                
                const response = await fetch('http://localhost:8000/transcribe', {
                    method: 'POST',
                    body: formData
                });
                
                if (response.ok) {
                    const result = await response.json();
                    const transcribedText = result.text;
                    status.innerHTML = `üìù You said: "${transcribedText}"`;
                    
                    // Send the transcribed text
                    setTimeout(() => sendMessage(transcribedText), 1000);
                } else {
                    throw new Error('Transcription failed');
                }
            } catch (error) {
                console.error('Transcription error:', error);
                status.innerHTML = '‚ùå Failed to transcribe audio';
                status.className = 'status error';
            }
        }
        
        function sendMessage(message) {
            status.innerHTML = '<div class="loading"></div>AI is thinking...';
            status.className = 'status';
            
            // Clear any existing audio queue to prevent overlapping
            audioQueue = [];
            isPlayingAudio = false;
            
            const ws = new WebSocket(WS_URL);
            let audioCount = 0;
            
            ws.onopen = () => {
                const selectedVoice = voiceSelect.value;
                ws.send(JSON.stringify({
                    type: 'text_input',
                    text: message,
                    voice_id: selectedVoice
                }));
            };
            
            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);
                
                if (data.type === 'text_chunk') {
                    // Just show that AI is responding, don't show text
                    status.innerHTML = 'ü§ñ AI is responding...';
                    
                } else if (data.type === 'audio_chunk') {
                    audioCount++;
                    
                    // Show audio playing status
                    status.innerHTML = `üîä AI is speaking... (${audioCount})`;
                    status.className = 'status audio-indicator';
                    
                    // Add audio to queue for sequential playback
                    addAudioToQueue(data.audio_data);
                    
                } else if (data.type === 'stream_complete') {
                    status.innerHTML = '‚úÖ AI finished speaking!';
                    status.className = 'status';
                    ws.close();
                    
                } else if (data.type === 'error') {
                    status.innerHTML = '‚ùå Error: ' + data.message;
                    status.className = 'status error';
                    ws.close();
                }
            };
            
            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
                status.innerHTML = '‚ùå Connection failed. Make sure backend is running.';
                status.className = 'status error';
            };
            
            ws.onclose = () => {
                console.log('WebSocket connection closed');
            };
        }
        
        // Audio queue management
        function playNextAudio() {
            if (audioQueue.length === 0) {
                isPlayingAudio = false;
                return;
            }
            
            isPlayingAudio = true;
            const audioData = audioQueue.shift();
            const audio = new Audio('data:audio/mpeg;base64,' + audioData);
            
            audio.onended = () => {
                playNextAudio(); // Play next audio when current one ends
            };
            
            audio.onerror = () => {
                console.error('Audio playback failed');
                playNextAudio(); // Continue to next audio even if one fails
            };
            
            audio.play().catch(e => {
                console.log('Audio autoplay failed:', e);
                status.innerHTML = 'üîä Click anywhere to enable audio, then try again';
                isPlayingAudio = false;
            });
        }
        
        function addAudioToQueue(audioData) {
            audioQueue.push(audioData);
            if (!isPlayingAudio) {
                playNextAudio();
            }
        }
        
        // Enable audio on first user interaction
        document.addEventListener('click', () => {
            // Create a silent audio context to enable autoplay
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            audioContext.resume();
        }, { once: true });
    </script>
</body>
</html>
