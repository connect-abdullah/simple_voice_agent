# ğŸ¤ Voice Agent

A pure voice-to-voice AI agent with real-time streaming responses and voice selection.

## âœ¨ Features

- ğŸ¤ **Voice-only interface** - Pure speech interaction
- ğŸ¤– **Real-time streaming** AI responses using OpenAI GPT-4
- ğŸ”Š **Sequential audio playback** - No overlapping voices
- ğŸµ **Voice selection** - Choose from 3 ElevenLabs voices
- ğŸ¯ **Whisper transcription** - Local + OpenAI API fallback
- âš¡ **Instant responses** - AI speaks as it thinks

## Setup

1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Create `.env` file:**
   ```
   OPENAI_API_KEY=your_openai_api_key_here
   ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
   ```

3. **Install system dependencies:**
   ```bash
   # macOS
   brew install portaudio ffmpeg
   
   # Ubuntu/Debian
   sudo apt-get install portaudio19-dev ffmpeg
   ```

## ğŸš€ Quick Start

**One-command startup:**
```bash
python start.py
```

This will:
- âœ… Check dependencies and environment
- ğŸš€ Start the FastAPI backend (port 8000)
- ğŸŒ Start the web frontend (port 3000)
- ğŸ¯ Display service URLs
- ğŸ”„ Handle graceful shutdown with Ctrl+C

**Then open:** `http://localhost:3000`

### Manual Startup

**Backend (Terminal 1):**
```bash
python backend/main.py
```

**Frontend (Terminal 2):**
```bash
python web-frontend/server.py
```

## API Endpoints

- `GET /` - Health check
- `GET /voices` - Get available voices  
- `POST /transcribe` - Transcribe audio to text
- `WebSocket /stream` - **Real-time streaming conversation**

## ğŸ§ª Testing

Run comprehensive tests:
```bash
python -m pytest tests/ -v
```

Individual test files:
- `tests/test_backend.py` - Backend API tests
- `tests/test_frontend.py` - Frontend server tests  
- `tests/test_audio_pipeline.py` - Complete audio pipeline tests

## ğŸ¯ Usage

### Web Interface
1. **Select a voice** from the dropdown (Rachel, Domi, or Callum)
2. **Click "ğŸ¤ Start Recording"** to speak
3. **Speak your message** clearly
4. **Click "â¹ï¸ Stop Recording"** when done
5. **Listen** as the AI responds with streaming audio

### Voice Selection
- **Rachel** - Calm and professional female voice
- **Domi** - Strong and confident female voice  
- **Callum** - Gravelly voice with unsettling edge

## ğŸ”„ How It Works

This voice agent uses **true streaming** for the fastest possible response times:

1. **ğŸ¤ Voice Input**: Record your voice â†’ Whisper transcription
2. **ğŸ¤– GPT-4 Streaming**: AI generates text in real-time chunks
3. **ğŸ”Š TTS Generation**: Text chunks are immediately converted to audio (ElevenLabs/OpenAI)
4. **ğŸµ Sequential Playback**: Audio chunks play one after another (no overlapping)
5. **âš¡ Real-time**: You hear the AI speak as it generates the response

**Result**: Natural, responsive voice conversations with zero text display!

## ğŸ“ Project Structure

```
voice_agent/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ main.py                    # FastAPI backend with WebSocket streaming
â”œâ”€â”€ web-frontend/
â”‚   â”œâ”€â”€ index.html                 # Voice-only web interface
â”‚   â””â”€â”€ server.py                  # Simple HTTP server for frontend
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ llm.py                     # OpenAI GPT-4 streaming integration
â”‚   â”œâ”€â”€ speechToText.py            # Speech transcription (Whisper local + API)
â”‚   â”œâ”€â”€ simple_tts.py              # Streaming TTS (ElevenLabs + OpenAI fallback)
â”‚   â””â”€â”€ record.py                  # Audio recording utilities
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_backend.py            # Backend API tests
â”‚   â”œâ”€â”€ test_frontend.py            # Frontend server tests
â”‚   â””â”€â”€ test_audio_pipeline.py     # Complete audio pipeline tests
â”œâ”€â”€ models/                        # Whisper model cache (auto-created)
â”œâ”€â”€ config.py                      # Configuration and voice settings
â”œâ”€â”€ main.py                        # Command-line interface
â”œâ”€â”€ start.py                       # One-command startup script
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # This file
```

## ğŸ”§ Technical Details

### Backend
- **FastAPI** with WebSocket support
- **Port**: 8000
- **Endpoints**: REST API + WebSocket streaming

### Frontend
- **Pure HTML/JavaScript** - No framework dependencies
- **Port**: 3000
- **Features**: Voice recording, real-time audio playback, voice selection

### Models
- **Whisper**: Local faster-whisper model (cached in `models/` folder)
- **Fallback**: OpenAI Whisper API if local model fails
- **TTS**: ElevenLabs (primary) with OpenAI TTS fallback

## ğŸ“ Notes

- The `models/` folder is auto-created for Whisper model caching
- Voice selection uses ElevenLabs free tier voices
- Audio playback is sequential to prevent overlapping
- All audio is streamed in real-time via WebSocket

## ğŸ› Troubleshooting

### Audio Not Playing
- **First time**: Click anywhere on the page to enable audio autoplay
- **Browser permissions**: Allow microphone access when prompted
- **Check console**: Open browser DevTools (F12) for error messages

### Backend Not Starting
- **Port 8000 in use**: Kill existing process: `lsof -ti:8000 | xargs kill -9`
- **Missing dependencies**: Run `pip install -r requirements.txt`
- **API keys**: Ensure `.env` file has valid keys

### Frontend Not Loading
- **Port 3000 in use**: Kill existing process: `lsof -ti:3000 | xargs kill -9`
- **Check backend**: Ensure backend is running on port 8000
- **Browser cache**: Try hard refresh (Ctrl+Shift+R / Cmd+Shift+R)

### Transcription Issues
- **Local Whisper fails**: Automatically falls back to OpenAI API
- **Slow transcription**: First run downloads model (~500MB)
- **Model cache**: Stored in `models/` folder (can be deleted to re-download)

## ğŸ“¦ Dependencies

- **Python 3.8+**
- **OpenAI API key** (for GPT-4 and Whisper fallback)
- **ElevenLabs API key** (for voice synthesis)
- **faster-whisper** (for local speech recognition)
- **FastAPI + Uvicorn** (backend server)
- **WebSockets** (real-time communication)

## ğŸ“„ License

This project is for personal/educational use. Ensure you comply with:
- OpenAI API Terms of Service
- ElevenLabs API Terms of Service
- Local data privacy regulations
